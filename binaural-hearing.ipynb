{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binaural Hearing\n",
    "\n",
    "[return to main page](index.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaural Correlation, Degree of Coherence\n",
    "\n",
    "This exercise examines the degree of coherence $k$ between right and left ear using noise signals.\n",
    "You can find more information in the (non-public) lecture notes on slides 4-29 to 4-31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fs = 44100\n",
    "dur = 1  # seconds\n",
    "ks = np.linspace(0, 1, 11)\n",
    "stddev = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length = int(dur * fs)\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "for k in ks:\n",
    "    R = [[1, k],\n",
    "         [k, 1]]\n",
    "    L, V = np.linalg.eig(R)\n",
    "    L.shape = 1, -1  # turn L into row vector\n",
    "    W = V * np.sqrt(L)\n",
    "    # create a new random signal in each iteration:\n",
    "    stereo_noise = np.random.normal(scale=stddev, size=(length, 2))\n",
    "    outsig = np.dot(stereo_noise, W.T)  # matrix product\n",
    "    sf.write('outdata/noise_k{:.1f}.wav'.format(k), outsig, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates several WAV files containing noise.\n",
    "The degree of coherence $k$ between both channels is part of the\n",
    "respective filename.\n",
    "\n",
    "*Exercise:* Listen to the different files and note how you perceive different degrees of\n",
    "coherence.\n",
    "\n",
    "$k=1.0$<audio src=\"outdata/noise_k1.0.wav\" controls></audio>\n",
    "[outdata/noise_k1.0.wav](outdata/noise_k1.0.wav)\n",
    "\n",
    "$k=0.9$<audio src=\"outdata/noise_k0.9.wav\" controls></audio>\n",
    "[outdata/noise_k0.9.wav](outdata/noise_k0.9.wav)\n",
    "\n",
    "$k=0.8$<audio src=\"outdata/noise_k0.8.wav\" controls></audio>\n",
    "[outdata/noise_k0.8.wav](outdata/noise_k0.8.wav)\n",
    "\n",
    "$k=0.7$<audio src=\"outdata/noise_k0.7.wav\" controls></audio>\n",
    "[outdata/noise_k0.7.wav](outdata/noise_k0.7.wav)\n",
    "\n",
    "$k=0.6$<audio src=\"outdata/noise_k0.6.wav\" controls></audio>\n",
    "[outdata/noise_k0.6.wav](outdata/noise_k0.6.wav)\n",
    "\n",
    "$k=0.5$<audio src=\"outdata/noise_k0.5.wav\" controls></audio>\n",
    "[outdata/noise_k0.5.wav](outdata/noise_k0.5.wav)\n",
    "\n",
    "$k=0.4$<audio src=\"outdata/noise_k0.4.wav\" controls></audio>\n",
    "[outdata/noise_k0.4.wav](outdata/noise_k0.4.wav)\n",
    "\n",
    "$k=0.3$<audio src=\"outdata/noise_k0.3.wav\" controls></audio>\n",
    "[outdata/noise_k0.3.wav](outdata/noise_k0.3.wav)\n",
    "\n",
    "$k=0.2$<audio src=\"outdata/noise_k0.2.wav\" controls></audio>\n",
    "[outdata/noise_k0.2.wav](outdata/noise_k0.2.wav)\n",
    "\n",
    "$k=0.1$<audio src=\"outdata/noise_k0.1.wav\" controls></audio>\n",
    "[outdata/noise_k0.1.wav](outdata/noise_k0.1.wav)\n",
    "\n",
    "$k=0.0$<audio src=\"outdata/noise_k0.0.wav\" controls></audio>\n",
    "[outdata/noise_k0.0.wav](outdata/noise_k0.0.wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binaural Unmasking\n",
    "\n",
    "Create audio examples based on slide 4-33.\n",
    "\n",
    "To do that, convolve the given HRIRs (stored in the files `data/hrir00.wav`,\n",
    "`data/hrir45.wav` and `data/hrir90.wav`) on the one hand with an arbitrary\n",
    "speech signal (e.g. from the `data/` directory), on the other hand with a noise signal\n",
    "(use the function [numpy.random.normal()](http://docs.scipy.org/doc/numpy/reference/generated/numpy.random.normal.html)).\n",
    "\n",
    "Add speech and noise in different combinations of angles of incidence.\n",
    "Amplify or attenuate speech and noise in a way that the speech is just barely\n",
    "understandable.\n",
    "\n",
    "Listen to the different combinations.\n",
    "In which combination can you understand the speech better or worse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaural Time Difference/Interaural Level Difference\n",
    "\n",
    "Two important *cues* for spatial hearing are ITD and ILD.\n",
    "\n",
    "*Exercise:* Click and learn:\n",
    "\n",
    "* Watch (and listen to!) the videos on this page: http://auditoryneuroscience.com/topics/binaural-cue-demos\n",
    "\n",
    "* Here is an interactive example: http://auditoryneuroscience.com/topics/time-intensity-trading\n",
    "\n",
    "*Exercise (only if you happen to have access to MatlabÂ®):* Do the listening test described on this page: http://auditoryneuroscience.com/topics/ITD-ILD-practical\n",
    "\n",
    "*Exercise:* Try to calculate the ITD as function of the angle of incidence using a\n",
    "very much simplified head model. Assume a spherical head with ear holes on\n",
    "exactly opposite points on the sphere.\n",
    "Make the head radius an adjustable parameter in your calculations; use\n",
    "8.75 cm as default value.\n",
    "Assume further, that the sound source is sufficiently far away, so that the\n",
    "angle of incidence is constant on the whole sphere.\n",
    "\n",
    "What is the maximum distance in the path from the sound source to the two ear\n",
    "holes, respectively?\n",
    "\n",
    "What time difference does that correspond to, assuming the speed of sound\n",
    "$c = 343 \\text{ m/s}$?\n",
    "\n",
    "Plot the ITD as a function of angle of incidence for a given head radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions\n",
    "\n",
    "If you had problems solving some of the exercises, don't despair!\n",
    "Have a look at the [example solutions](binaural-hearing-solutions.ipynb).\n",
    "\n",
    "<p xmlns:dct=\"http://purl.org/dc/terms/\">\n",
    "  <a rel=\"license\"\n",
    "     href=\"http://creativecommons.org/publicdomain/zero/1.0/\">\n",
    "    <img src=\"http://i.creativecommons.org/p/zero/1.0/88x31.png\" style=\"border-style: none;\" alt=\"CC0\" />\n",
    "  </a>\n",
    "  <br />\n",
    "  To the extent possible under law,\n",
    "  <span rel=\"dct:publisher\" resource=\"[_:publisher]\">the person who associated CC0</span>\n",
    "  with this work has waived all copyright and related or neighboring\n",
    "  rights to this work.\n",
    "</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
